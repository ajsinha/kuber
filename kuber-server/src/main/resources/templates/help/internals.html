<!DOCTYPE html>
<!--
  ~ Copyright © 2025-2030, All Rights Reserved
  ~ Ashutosh Sinha | Email: ajsinha@gmail.com
  ~ Patent Pending
  -->
<html xmlns:th="http://www.thymeleaf.org">
<head th:replace="~{layout :: head('System Internals')}"></head>
<body class="d-flex flex-column min-vh-100">

<nav th:replace="~{layout :: navbar}"></nav>

<main class="flex-fill">
    <div class="container-fluid py-4">
        <!-- Breadcrumb -->
        <nav aria-label="breadcrumb" class="mb-4">
            <ol class="breadcrumb">
                <li class="breadcrumb-item"><a href="/help"><i class="fas fa-book me-1"></i>Help</a></li>
                <li class="breadcrumb-item active" aria-current="page">System Internals</li>
            </ol>
        </nav>

        <!-- Content -->
        <div class="row">
            <div class="col-lg-10 mx-auto">
                <!-- Header -->
                <h1 class="display-5 mb-4"><i class="fas fa-cogs me-3 text-primary"></i>System Internals</h1>
                
                <div class="alert alert-info">
                    <i class="fas fa-info-circle me-2"></i>
                    <strong>Version 1.7.4</strong> - Deep dive into <span th:text="${appName} ?: 'Kuber'">Kuber</span>'s 
                    architecture and operational mechanics.
                </div>

                <!-- Table of Contents -->
                <div class="card mb-5">
                    <div class="card-header bg-dark text-white">
                        <h5 class="mb-0"><i class="fas fa-list me-2"></i>Table of Contents</h5>
                    </div>
                    <div class="card-body">
                        <div class="row">
                            <div class="col-md-6">
                                <ol>
                                    <li><a href="#memory-management">Memory Management</a></li>
                                    <li><a href="#key-management">Key Management</a></li>
                                    <li><a href="#persistence-management">Persistence Management</a></li>
                                    <li><a href="#compaction">Compaction &amp; Optimization</a></li>
                                    <li><a href="#thread-management">Thread Management</a></li>
                                </ol>
                            </div>
                            <div class="col-md-6">
                                <ol start="6">
                                    <li><a href="#data-safety">Data Safety &amp; Recovery</a></li>
                                    <li><a href="#concurrency-safety">Concurrency Safety &amp; Shutdown</a></li>
                                    <li><a href="#shutdown-utility">Shutdown Utility</a> <span class="badge bg-success">v1.3.6</span></li>
                                    <li><a href="#event-publishing">Event Publishing</a></li>
                                </ol>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- 1. Memory Management -->
                <section id="memory-management" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header bg-success text-white">
                            <h2 class="mb-0"><i class="fas fa-memory me-2"></i>1. Memory Management</h2>
                        </div>
                        <div class="card-body">
                            <h4>1.1 Hybrid Memory Architecture</h4>
                            <p>Kuber uses a <strong>Hybrid Memory Architecture</strong> inspired by Aerospike's storage model. This design ensures optimal memory usage while maintaining sub-millisecond response times.</p>
                            
                            <div class="alert alert-info">
                                <strong><i class="fas fa-info-circle me-2"></i>Core Principle:</strong> 
                                ALL keys are ALWAYS kept in memory (KeyIndex). Values can be hot (in memory) or cold (on disk only).
                            </div>

                            <h5>Memory Structure</h5>
                            <pre class="bg-dark text-white p-3 rounded">
┌─────────────────────────────────────────────────────────────────────┐
│                         JVM HEAP MEMORY                              │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  ┌─────────────────────────────┐  ┌─────────────────────────────┐   │
│  │      KeyIndex (per region)   │  │    Value Cache (Caffeine)   │   │
│  ├─────────────────────────────┤  ├─────────────────────────────┤   │
│  │ • ALL keys always in memory │  │ • Hot values (recently used)│   │
│  │ • ~100 bytes per key        │  │ • Subject to eviction       │   │
│  │ • O(1) lookup               │  │ • LRU eviction policy       │   │
│  │ • Never evicted             │  │ • Configurable size limit   │   │
│  └─────────────────────────────┘  └─────────────────────────────┘   │
│                                                                      │
│  Optional: Off-Heap KeyIndex (DRAM outside Java heap)               │
│  ┌─────────────────────────────────────────────────────────────┐    │
│  │ • Zero GC pressure           • Memory-mapped direct buffers │    │
│  │ • Millions of keys           • Auto-growing buffers         │    │
│  └─────────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────────┐
│                      PERSISTENCE LAYER (DISK)                        │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐            │
│  │ RocksDB  │  │  SQLite  │  │   LMDB   │  │ MongoDB  │            │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘            │
│                      Cold values stored here                         │
└─────────────────────────────────────────────────────────────────────┘</pre>

                            <h4 class="mt-4">1.2 Value Retrieval Flow</h4>
                            <p>When a client requests a key using <code>GET</code>:</p>
                            
                            <pre class="bg-dark text-white p-3 rounded">
GET key → KeyIndex Check
             │
             ├── Key NOT in index → Return NULL (O(1), no disk I/O)
             │
             └── Key EXISTS in index
                      │
                      ├── Value in memory cache → Return immediately (O(1))
                      │
                      └── Value NOT in memory (cold)
                               │
                               └── Load from persistence store
                                        │
                                        ├── Found → Add to memory cache, return value
                                        │
                                        └── Not found → Cleanup index, return NULL</pre>

                            <div class="row mt-4">
                                <div class="col-md-6">
                                    <div class="card border-success">
                                        <div class="card-header bg-success text-white">Memory Cache Hit</div>
                                        <div class="card-body">
                                            <ul class="mb-0">
                                                <li>Latency: &lt; 1 microsecond</li>
                                                <li>No disk I/O</li>
                                                <li>Updates access time for LRU</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-6">
                                    <div class="card border-warning">
                                        <div class="card-header bg-warning">Cold Value (Disk Read)</div>
                                        <div class="card-body">
                                            <ul class="mb-0">
                                                <li>Latency: 1-10 milliseconds</li>
                                                <li>Reads from persistence store</li>
                                                <li>Promotes value to memory cache</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <h4 class="mt-4">1.3 Automatic Memory Protection (OOM Prevention)</h4>
                            <p>Kuber includes a <strong>Memory Watcher Service</strong> that prevents out-of-memory crashes:</p>

                            <pre class="bg-dark text-white p-3 rounded">
┌─────────────────────────────────────────────────────────────────────┐
│                    MEMORY WATCHER SERVICE                            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  Monitoring: Every 5 seconds (configurable)                         │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐    │
│  │ Heap Usage Monitoring                                        │    │
│  │                                                              │    │
│  │  0%────────────────50%────────────────85%────────────100%   │    │
│  │  │                  │                  │                │    │    │
│  │  │   Normal Zone    │   Warning Zone   │  DANGER ZONE   │    │    │
│  │  │   (No action)    │   (Prepare)      │  (EVICT NOW)   │    │    │
│  │  └──────────────────┴──────────────────┴────────────────┘    │    │
│  │                     ▲                  ▲                      │    │
│  │              Low Watermark      High Watermark                │    │
│  │                 (50%)              (85%)                      │    │
│  └─────────────────────────────────────────────────────────────┘    │
│                                                                      │
│  When heap &gt; 85%:                                                   │
│  1. Persist cold values to disk                                     │
│  2. Evict values from memory cache (keys stay in KeyIndex!)        │
│  3. Update KeyIndex: ValueLocation.BOTH → ValueLocation.DISK       │
│  4. Repeat until heap &lt; 50%                                         │
│                                                                      │
│  Safety: Max 100 eviction iterations per cycle                      │
└─────────────────────────────────────────────────────────────────────┘</pre>

                            <h5>Memory Watcher Configuration</h5>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Property</th><th>Default</th><th>Description</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td><code>kuber.cache.memory-watcher-enabled</code></td><td>true</td><td>Enable/disable automatic memory management</td></tr>
                                    <tr><td><code>kuber.cache.memory-watcher-interval-ms</code></td><td>5000</td><td>Check interval in milliseconds</td></tr>
                                    <tr><td><code>kuber.cache.memory-high-watermark-percent</code></td><td>85</td><td>Start eviction when heap exceeds this %</td></tr>
                                    <tr><td><code>kuber.cache.memory-low-watermark-percent</code></td><td>50</td><td>Stop eviction when heap drops below this %</td></tr>
                                    <tr><td><code>kuber.cache.memory-eviction-batch-size</code></td><td>1000</td><td>Entries evicted per batch</td></tr>
                                </tbody>
                            </table>

                            <div class="alert alert-success">
                                <strong><i class="fas fa-check-circle me-2"></i>Key Guarantee:</strong>
                                During eviction, only VALUES are removed from memory. KEYS always remain in the KeyIndex, 
                                ensuring EXISTS and KEYS operations remain O(1) even under memory pressure.
                            </div>
                        </div>
                    </div>
                </section>

                <!-- 2. Key Management -->
                <section id="key-management" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header bg-primary text-white">
                            <h2 class="mb-0"><i class="fas fa-key me-2"></i>2. Key Management</h2>
                        </div>
                        <div class="card-body">
                            <h4>2.1 KeyIndex Architecture</h4>
                            <p>The KeyIndex is the heart of Kuber's O(1) key operations. Every key ever written is tracked here.</p>

                            <pre class="bg-dark text-white p-3 rounded">
┌─────────────────────────────────────────────────────────────────────┐
│                         KEY INDEX ENTRY                              │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  KeyIndexEntry {                                                    │
│      String key;           // The actual key                        │
│      long valueSizeBytes;  // Size of value (for memory estimation)│
│      Instant createdAt;    // When key was first created           │
│      Instant expiresAt;    // TTL expiration time (nullable)       │
│      String valueType;     // STRING, HASH, LIST, etc.             │
│      ValueLocation location; // MEMORY, DISK, or BOTH              │
│      long accessCount;     // Access count for statistics          │
│      Instant lastAccessedAt; // For LRU tracking                   │
│  }                                                                  │
│                                                                      │
│  Memory footprint: ~100-150 bytes per key                           │
│  With 10 million keys: ~1.5 GB                                      │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘</pre>

                            <h4 class="mt-4">2.2 On-Heap vs Off-Heap KeyIndex</h4>
                            <div class="row">
                                <div class="col-md-6">
                                    <div class="card h-100">
                                        <div class="card-header bg-light">On-Heap (Default)</div>
                                        <div class="card-body">
                                            <p><code>kuber.cache.off-heap-key-index=false</code></p>
                                            <ul>
                                                <li>Uses ConcurrentHashMap</li>
                                                <li>Subject to GC pauses</li>
                                                <li>Good for &lt; 5 million keys</li>
                                                <li>Simpler debugging</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-6">
                                    <div class="card h-100">
                                        <div class="card-header bg-success text-white">Off-Heap - Segmented (v1.3.2)</div>
                                        <div class="card-body">
                                            <p><code>kuber.cache.off-heap-key-index=true</code></p>
                                            <ul>
                                                <li>Multiple 1GB ByteBuffer segments</li>
                                                <li>Zero GC pressure</li>
                                                <li>Supports >2GB per region</li>
                                                <li>Ideal for 10+ million keys</li>
                                                <li>Auto-compaction at 30% fragmentation</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            
                            <h4 class="mt-4">2.3 Off-Heap Segmented Buffer Architecture (v1.3.2)</h4>
                            <div class="alert alert-info">
                                <strong>Why Segmented?</strong> Java's ByteBuffer.allocateDirect() is limited to ~2GB per buffer. 
                                Kuber uses multiple 1GB segments to support 8GB+ per region.
                            </div>
                            <pre class="bg-dark text-white p-3 rounded">
┌─────────────────────────────────────────────────────────────────────┐
│                    OFF-HEAP KEY INDEX                                │
├─────────────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                  │
│  │  Segment 0  │  │  Segment 1  │  │  Segment 2  │  ...             │
│  │   (1 GB)    │  │   (1 GB)    │  │   (1 GB)    │                  │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘                  │
│         │                │                │                          │
│         └────────────────┴────────────────┴──────────────────────────│
│                             │                                        │
│              Global Offset (long): position across segments          │
├─────────────────────────────────────────────────────────────────────┤
│  On-Heap Index:  ConcurrentHashMap&lt;String, Long&gt;  (key → offset)    │
└─────────────────────────────────────────────────────────────────────┘</pre>

                            <h5 class="mt-3">Memory Layout Per Key Entry</h5>
                            <table class="table table-bordered table-sm">
                                <thead class="table-light">
                                    <tr><th>Bytes</th><th>Field</th><th>Type</th><th>Description</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td>2</td><td>keyLength</td><td>short</td><td>Length of key bytes</td></tr>
                                    <tr><td>variable</td><td>keyBytes</td><td>byte[]</td><td>UTF-8 encoded key</td></tr>
                                    <tr><td>8</td><td>expiresAt</td><td>long</td><td>TTL timestamp (-1 = never)</td></tr>
                                    <tr><td>1</td><td>location</td><td>byte</td><td>0=MEMORY, 1=DISK, 2=BOTH</td></tr>
                                    <tr><td>4</td><td>valueSize</td><td>int</td><td>Size of value in bytes</td></tr>
                                    <tr><td>8</td><td>lastAccess</td><td>long</td><td>Last access timestamp</td></tr>
                                    <tr><td>4</td><td>accessCount</td><td>int</td><td>Access counter for LFU</td></tr>
                                </tbody>
                            </table>
                            <p class="small text-muted">Total metadata: 27 bytes + key length</p>

                            <h5 class="mt-3">Off-Heap Configuration</h5>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Property</th><th>Default</th><th>Description</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td><code>kuber.cache.off-heap-key-index</code></td><td>false</td><td>Enable off-heap storage</td></tr>
                                    <tr><td><code>kuber.cache.off-heap-key-index-initial-size-mb</code></td><td>16</td><td>Initial segment size (MB)</td></tr>
                                    <tr><td><code>kuber.cache.off-heap-key-index-max-size-mb</code></td><td>8192</td><td>Max total size across all segments (MB)</td></tr>
                                </tbody>
                            </table>

                            <h4 class="mt-4">2.4 Key Operation Performance</h4>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Operation</th><th>Complexity</th><th>Disk I/O</th><th>Notes</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td><code>EXISTS key</code></td><td>O(1)</td><td>Never</td><td>Pure memory lookup in KeyIndex</td></tr>
                                    <tr><td><code>KEYS pattern</code></td><td>O(n)</td><td>Never</td><td>Scans KeyIndex only, not disk</td></tr>
                                    <tr><td><code>DBSIZE</code></td><td>O(1)</td><td>Never</td><td>Returns keyIndex.size()</td></tr>
                                    <tr><td><code>TYPE key</code></td><td>O(1)</td><td>Never</td><td>Stored in KeyIndex metadata</td></tr>
                                    <tr><td><code>TTL key</code></td><td>O(1)</td><td>Never</td><td>Stored in KeyIndex metadata</td></tr>
                                </tbody>
                            </table>

                            <h4 class="mt-4">2.5 Key Lifecycle</h4>
                            <pre class="bg-dark text-white p-3 rounded">
SET key value
    │
    ▼
┌───────────────────┐     ┌───────────────────┐     ┌───────────────────┐
│ 1. Update KeyIndex│ ──▶ │ 2. Add to Cache   │ ──▶ │ 3. Persist Async  │
│ (location=BOTH)   │     │ (value in memory) │     │ (write to disk)   │
└───────────────────┘     └───────────────────┘     └───────────────────┘

Memory Pressure (Eviction)
    │
    ▼
┌───────────────────┐     ┌───────────────────┐     ┌───────────────────┐
│ 1. Persist Value  │ ──▶ │ 2. Remove from    │ ──▶ │ 3. Update KeyIndex│
│ (ensure on disk)  │     │    Memory Cache   │     │ (location=DISK)   │
└───────────────────┘     └───────────────────┘     └───────────────────┘

DELETE key
    │
    ▼
┌───────────────────┐     ┌───────────────────┐     ┌───────────────────┐
│ 1. Remove from    │ ──▶ │ 2. Remove from    │ ──▶ │ 3. Delete from    │
│    KeyIndex       │     │    Memory Cache   │     │    Persistence    │
└───────────────────┘     └───────────────────┘     └───────────────────┘</pre>
                        </div>
                    </div>
                </section>

                <!-- 3. Persistence Management -->
                <section id="persistence-management" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header bg-info text-white">
                            <h2 class="mb-0"><i class="fas fa-database me-2"></i>3. Persistence Management</h2>
                        </div>
                        <div class="card-body">
                            <h4>3.1 Supported Persistence Backends</h4>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Backend</th><th>Use Case</th><th>Characteristics</th><th>Configuration</th></tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>RocksDB</strong> (Default)</td>
                                        <td>High performance, no external deps</td>
                                        <td>LSM-tree, embedded, fast writes</td>
                                        <td><code>kuber.persistence.type=lmdb</code></td>
                                    </tr>
                                    <tr>
                                        <td><strong>LMDB</strong></td>
                                        <td>Zero-copy reads, ACID transactions</td>
                                        <td>B+ tree, memory-mapped, crash-safe</td>
                                        <td><code>kuber.persistence.type=lmdb</code></td>
                                    </tr>
                                    <tr>
                                        <td><strong>SQLite</strong></td>
                                        <td>Portability, SQL queries</td>
                                        <td>Single file, ACID, SQL support</td>
                                        <td><code>kuber.persistence.type=sqlite</code></td>
                                    </tr>
                                    <tr>
                                        <td><strong>MongoDB</strong></td>
                                        <td>Distributed, flexible queries</td>
                                        <td>Document store, replication</td>
                                        <td><code>kuber.persistence.type=mongodb</code></td>
                                    </tr>
                                    <tr>
                                        <td><strong>Memory</strong></td>
                                        <td>Testing, volatile cache</td>
                                        <td>No persistence, pure cache</td>
                                        <td><code>kuber.persistence.type=memory</code></td>
                                    </tr>
                                </tbody>
                            </table>

                            <h4 class="mt-4">3.2 Write Path (v1.5.0)</h4>
                            <p>Individual writes support two modes configured via <code>kuber.persistence.sync-individual-writes</code>:</p>
                            
                            <div class="alert alert-info mb-3">
                                <strong>ASYNC Mode (default):</strong> Memory updated first, disk write in background - 10-100x faster<br>
                                <strong>SYNC Mode:</strong> Disk write completes before returning - maximum durability
                            </div>
                            
                            <pre class="bg-dark text-white p-3 rounded">
<span class="text-success">═══════════════════════════════════════════════════════════════════
  ASYNC MODE (default) - sync-individual-writes: false
═══════════════════════════════════════════════════════════════════</span>

Client SET Command
        │
        ▼
┌───────────────────────────────────────────────────────────────────┐
│                       CacheService.set()                           │
│                                                                    │
│  1. Validate region exists                                         │
│  2. Apply attribute mapping (if JSON)                             │
│  3. Create CacheEntry with TTL, timestamps                        │
│  4. putEntry() →                                                   │
│       │                                                            │
│       ├── 1. Update KeyIndex (IMMEDIATE)     ← Key is "on disk"   │
│       ├── 2. Update Value Cache (IMMEDIATE)  ← Data readable now  │
│       └── 3. saveEntryAsync() (BACKGROUND)   ← Non-blocking       │
│                                                                    │
│  Return: +OK (after memory update, ~0.01-0.1ms)                   │
└───────────────────────────────────────────────────────────────────┘
        │
        │  (background thread)
        ▼
┌───────────────────────────────────────────────────────────────────┐
│              PersistenceStore.saveEntryAsync()                     │
│              Eventually written to disk                            │
└───────────────────────────────────────────────────────────────────┘

<span class="text-warning">═══════════════════════════════════════════════════════════════════
  SYNC MODE - sync-individual-writes: true
═══════════════════════════════════════════════════════════════════</span>

Client SET Command
        │
        ▼
┌───────────────────────────────────────────────────────────────────┐
│                       CacheService.set()                           │
│                                                                    │
│  1. Validate region exists                                         │
│  2. Apply attribute mapping (if JSON)                             │
│  3. Create CacheEntry with TTL, timestamps                        │
│  4. putEntry() →                                                   │
│       │                                                            │
│       ├── 1. saveEntry() (BLOCKING)          ← Wait for disk      │
│       │       └── fsync() to disk                                 │
│       ├── 2. Update KeyIndex (after disk)    ← Confirmed on disk  │
│       └── 3. Update Value Cache              ← Data readable      │
│                                                                    │
│  Return: +OK (after disk write, ~1-5ms)                           │
└───────────────────────────────────────────────────────────────────┘</pre>

                            <h5 class="mt-4">Write Mode Comparison</h5>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Aspect</th><th>ASYNC (default)</th><th>SYNC</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td>Latency</td><td>~0.01-0.1ms</td><td>~1-5ms</td></tr>
                                    <tr><td>Throughput</td><td>10,000-100,000 ops/sec</td><td>200-1,000 ops/sec</td></tr>
                                    <tr><td>Durability</td><td>Eventually consistent</td><td>Immediate</td></tr>
                                    <tr><td>Crash Risk</td><td>Entry may be lost</td><td>No data loss</td></tr>
                                    <tr><td>Use Case</td><td>Performance critical</td><td>Durability critical</td></tr>
                                </tbody>
                            </table>

                            <h4 class="mt-4">3.3 Region-Based Organization</h4>
                            <p>Data is organized into <strong>regions</strong> for logical separation:</p>
                            <pre class="bg-dark text-white p-3 rounded">
./data/rocksdb/
├── default/          # Default region
│   ├── 000001.sst    # RocksDB SST files
│   └── CURRENT
├── customers/        # Customer data region
│   ├── 000001.sst
│   └── CURRENT
└── products/         # Product catalog region
    ├── 000001.sst
    └── CURRENT

Each region has:
• Its own KeyIndex (in memory)
• Its own Value Cache (Caffeine instance)
• Its own persistence directory/collection
• Independent memory limits</pre>
                        </div>
                    </div>
                </section>

                <!-- 4. Compaction and Optimization -->
                <section id="compaction" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header bg-warning text-dark">
                            <h2 class="mb-0"><i class="fas fa-compress-arrows-alt me-2"></i>4. Compaction &amp; Optimization</h2>
                        </div>
                        <div class="card-body">
                            <h4>4.1 Why Compaction Matters</h4>
                            <p>Databases like RocksDB and SQLite accumulate dead space from updates and deletes. Compaction reclaims this space and improves read performance.</p>

                            <div class="row">
                                <div class="col-md-6">
                                    <div class="card border-danger mb-3">
                                        <div class="card-header bg-danger text-white">Before Compaction</div>
                                        <div class="card-body">
                                            <ul class="mb-0">
                                                <li>Multiple SST files with overlapping keys</li>
                                                <li>Tombstones for deleted entries</li>
                                                <li>Fragmented disk space</li>
                                                <li>Slower read amplification</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-6">
                                    <div class="card border-success mb-3">
                                        <div class="card-header bg-success text-white">After Compaction</div>
                                        <div class="card-body">
                                            <ul class="mb-0">
                                                <li>Merged, optimized SST files</li>
                                                <li>Tombstones removed</li>
                                                <li>Disk space reclaimed</li>
                                                <li>Faster reads</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>

                            <h4 class="mt-4">4.2 When Compaction Runs</h4>
                            <pre class="bg-dark text-white p-3 rounded">
┌─────────────────────────────────────────────────────────────────────┐
│                   COMPACTION SCHEDULE (v1.2.6)                       │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  STARTUP COMPACTION (PersistenceMaintenanceService)                 │
│  ─────────────────────────────────────────────────────              │
│  • Runs AFTER Spring context initialization                         │
│  • BEFORE cache service loads data                                  │
│  • Ensures databases are optimized before serving requests          │
│                                                                      │
│  Sequence:                                                          │
│  Spring Ready → 10s wait → COMPACTION → 2s wait → Cache Init        │
│                                                                      │
│                                                                      │
│  SCHEDULED COMPACTION (RocksDbCompactionService)                    │
│  ─────────────────────────────────────────────────                  │
│  • Default: 2:00 AM daily                                           │
│  • Configurable via cron expression                                 │
│  • Non-blocking (runs in background)                                │
│                                                                      │
│  kuber.persistence.rocksdb.compaction-cron=0 0 2 * * ?              │
│                                                                      │
│  Examples:                                                          │
│  • "0 0 3 * * SUN"    → 3:00 AM every Sunday                       │
│  • "0 0 */6 * * ?"    → Every 6 hours                              │
│  • "0 30 1 * * ?"     → 1:30 AM daily                              │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘</pre>

                            <h4 class="mt-4">4.3 Backend-Specific Optimization</h4>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Backend</th><th>Operation</th><th>What It Does</th></tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>RocksDB</strong></td>
                                        <td><code>compactRange()</code></td>
                                        <td>Merges SST files, removes tombstones, reduces read amplification</td>
                                    </tr>
                                    <tr>
                                        <td><strong>SQLite</strong></td>
                                        <td><code>VACUUM</code></td>
                                        <td>Rebuilds database file, reclaims unused pages</td>
                                    </tr>
                                    <tr>
                                        <td><strong>LMDB</strong></td>
                                        <td>N/A (auto-balancing)</td>
                                        <td>B+ tree self-balances; no manual compaction needed</td>
                                    </tr>
                                    <tr>
                                        <td><strong>MongoDB</strong></td>
                                        <td><code>compact</code></td>
                                        <td>Managed by MongoDB server (WiredTiger auto-compacts)</td>
                                    </tr>
                                </tbody>
                            </table>

                            <h4 class="mt-4">4.4 Compaction Configuration</h4>
                            <pre class="bg-light p-3 rounded"><code># Enable/disable startup compaction
kuber.persistence.rocksdb.compaction-enabled=true

# Scheduled compaction cron (RocksDB only)
kuber.persistence.rocksdb.compaction-cron=0 0 2 * * ?</code></pre>
                            
                            <div class="alert alert-info mt-3">
                                <i class="fas fa-bolt me-2"></i>
                                <strong>Sequential Processing (v1.5.0):</strong>
                                Region databases are compacted/vacuumed sequentially during startup for data consistency.
                                This ensures no concurrent operations that could cause corruption.
                            </div>
                        </div>
                    </div>
                </section>

                <!-- 5. Thread Management -->
                <section id="thread-management" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header bg-secondary text-white">
                            <h2 class="mb-0"><i class="fas fa-tasks me-2"></i>5. Thread Management</h2>
                        </div>
                        <div class="card-body">
                            <h4>5.1 Thread Architecture</h4>
                            <pre class="bg-dark text-white p-3 rounded">
┌─────────────────────────────────────────────────────────────────────┐
│                       KUBER THREAD MODEL                             │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  MAIN THREADS                                                       │
│  ────────────────────────────────────────────────────               │
│  main                       Spring Boot startup                     │
│  kuber-startup-orchestrator Startup sequence coordination          │
│                                                                      │
│  SEQUENTIAL STARTUP (v1.5.0)                                        │
│  ────────────────────────────────────────────────────               │
│  All startup operations (compaction, loading) run sequentially      │
│  in the main startup thread for data consistency.                   │
│                                                                      │
│  REDIS PROTOCOL (Apache MINA)                                       │
│  ────────────────────────────────────────────────────               │
│  NioProcessor-[1-N]         I/O processing threads                  │
│  pool-[N]-thread-[M]        ExecutorFilter worker threads           │
│                              (CachedThreadPool for client handlers) │
│                                                                      │
│  SCHEDULED TASKS (Spring @Scheduled)                                │
│  ────────────────────────────────────────────────────               │
│  scheduling-1               TTL cleanup (every 60s)                 │
│                             Memory watcher (every 5s)               │
│                             Metrics collection (every 1m)           │
│                             Persistence expiration (every 60s)      │
│                             Replication heartbeat (every 5s)        │
│                             Scheduled compaction (cron)             │
│                                                                      │
│  AUTOLOAD                                                           │
│  ────────────────────────────────────────────────────               │
│  kuber-autoload             File scanning and processing           │
│                                                                      │
│  BACKUP/RESTORE (v1.5.0)                                            │
│  ────────────────────────────────────────────────────               │
│  kuber-backup               Periodic backup of all regions         │
│  kuber-restore-watcher      Monitors ./restore for backup files    │
│                                                                      │
│  ASYNC PERSISTENCE (v1.5.0)                                         │
│  ────────────────────────────────────────────────────               │
│  persistence-async-save-0   Region-partitioned async writes        │
│  persistence-async-save-1   (hash of region name mod 4)            │
│  persistence-async-save-2   All writes for same region are         │
│  persistence-async-save-3   sequential, different regions parallel │
│                                                                      │
│  EVENT PUBLISHING                                                   │
│  ────────────────────────────────────────────────────               │
│  kuber-event-publisher-[N]  Async event publishing to destinations │
│  (Kafka, ActiveMQ, RabbitMQ, IBM MQ, File)                         │
│                                                                      │
│  HTTP SERVER (Spring/Tomcat)                                        │
│  ────────────────────────────────────────────────────               │
│  http-nio-8080-exec-[N]     REST API request handlers              │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘</pre>

                            <h4 class="mt-4">5.2 Scheduled Tasks</h4>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Task</th><th>Interval</th><th>Purpose</th><th>Protection</th></tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>TTL Cleanup</td>
                                        <td>60 seconds</td>
                                        <td>Remove expired entries from cache</td>
                                        <td>Checks <code>initialized.get()</code></td>
                                    </tr>
                                    <tr>
                                        <td>Memory Watcher</td>
                                        <td>5 seconds</td>
                                        <td>Monitor heap and evict if needed</td>
                                        <td>Checks <code>cacheService.isInitialized()</code></td>
                                    </tr>
                                    <tr>
                                        <td>Metrics Collection</td>
                                        <td>1 minute</td>
                                        <td>Record cache hit rates, sizes</td>
                                        <td>N/A (safe to run early)</td>
                                    </tr>
                                    <tr>
                                        <td>Persistence Expiration</td>
                                        <td>60 seconds</td>
                                        <td>Clean expired entries from disk</td>
                                        <td>Checks <code>cacheService.isInitialized()</code></td>
                                    </tr>
                                    <tr>
                                        <td>Scheduled Compaction</td>
                                        <td>Cron (2 AM)</td>
                                        <td>Optimize RocksDB storage</td>
                                        <td>Checks <code>enabled.get()</code></td>
                                    </tr>
                                </tbody>
                            </table>

                            <h4 class="mt-4">5.3 Thread Safety Guarantees</h4>
                            <div class="row">
                                <div class="col-md-6">
                                    <div class="card">
                                        <div class="card-header bg-light">On-Heap KeyIndex</div>
                                        <div class="card-body">
                                            <code>ConcurrentHashMap</code> - lock-free reads, segment-level locking for writes
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-6">
                                    <div class="card">
                                        <div class="card-header bg-light">Off-Heap KeyIndex</div>
                                        <div class="card-body">
                                            <code>ReentrantReadWriteLock</code> - multiple concurrent readers, exclusive writer
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- 6. Data Safety and Recovery -->
                <section id="data-safety" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header bg-dark text-white">
                            <h2 class="mb-0"><i class="fas fa-shield-alt me-2"></i>6. Data Safety &amp; Recovery</h2>
                        </div>
                        <div class="card-body">
                            <h4>6.1 Data Durability Guarantees</h4>
                            <pre class="bg-dark text-white p-3 rounded">
┌─────────────────────────────────────────────────────────────────────┐
│                    DATA DURABILITY LEVELS                            │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  WRITE PATH DURABILITY                                              │
│  ─────────────────────────────────────────────                      │
│                                                                      │
│  SET command → KeyIndex ✓ → Value Cache ✓ → Persistence (async)    │
│                                                                      │
│  • KeyIndex update: Synchronous (immediate)                         │
│  • Value Cache update: Synchronous (immediate)                      │
│  • Persistence: Asynchronous (background)                           │
│                                                                      │
│  Data is SAFE when:                                                 │
│  ✓ Client receives OK response                                      │
│  ✓ Data is in memory (KeyIndex + Cache)                            │
│  ✓ Persistence write queued (will complete in background)          │
│                                                                      │
│                                                                      │
│  PERSISTENCE BACKEND GUARANTEES                                     │
│  ─────────────────────────────────────────────                      │
│                                                                      │
│  RocksDB:  • WAL (Write-Ahead Log) for crash recovery              │
│            • Configurable sync mode                                 │
│            • LSM-tree with compaction                               │
│                                                                      │
│  LMDB:     • Full ACID transactions                                 │
│            • Memory-mapped with OS sync                             │
│            • Copy-on-write (no corruption on crash)                 │
│                                                                      │
│  SQLite:   • Journal mode (WAL or rollback)                        │
│            • ACID transactions                                      │
│            • VACUUM for recovery                                    │
│                                                                      │
│  MongoDB:  • Write concern configurable                            │
│            • Replication for high availability                      │
│            • Journaling for durability                              │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘</pre>

                            <h4 class="mt-4">6.2 Startup Recovery Process</h4>
                            <p>When Kuber starts (or restarts), data is automatically recovered from persistence:</p>
                            
                            <pre class="bg-dark text-white p-3 rounded">
SYSTEM RESTART
      │
      ▼
┌───────────────────────────────────────────────────────────────────┐
│ Phase 1: Spring Context Initialization                            │
│ • Load all beans and configurations                               │
│ • Wait 10 seconds for stabilization                               │
└───────────────────────────────────────────────────────────────────┘
      │
      ▼
┌───────────────────────────────────────────────────────────────────┐
│ Phase 2: Persistence Maintenance                                   │
│ • RocksDB: Run compactRange() on all region databases             │
│ • SQLite: Run VACUUM on all database files                        │
│ • Ensures optimal read performance for recovery                   │
└───────────────────────────────────────────────────────────────────┘
      │
      ▼
┌───────────────────────────────────────────────────────────────────┐
│ Phase 3: Cache Service Initialization (DATA RECOVERY)             │
│                                                                    │
│ For each region:                                                   │
│   1. Load ALL keys from persistence → KeyIndex                    │
│      (keys marked as ValueLocation.DISK initially)                │
│                                                                    │
│   2. Load hot values (up to memory limit) → Value Cache           │
│      (update location to ValueLocation.BOTH)                      │
│                                                                    │
│   3. Remaining values stay on disk (cold)                         │
│      (accessed on-demand via GET)                                 │
│                                                                    │
│ Result: ALL keys searchable, hot values in memory                 │
└───────────────────────────────────────────────────────────────────┘
      │
      ▼
┌───────────────────────────────────────────────────────────────────┐
│ Phase 4: Redis Protocol Server                                     │
│ • Bind to port 6380                                               │
│ • Accept client connections                                        │
│ • NOW clients can connect with FULL DATA AVAILABLE               │
└───────────────────────────────────────────────────────────────────┘
      │
      ▼
┌───────────────────────────────────────────────────────────────────┐
│ Phase 5: Autoload Service                                          │
│ • Resume file monitoring                                           │
│ • Process any files added during downtime                         │
└───────────────────────────────────────────────────────────────────┘
      │
      ▼
┌───────────────────────────────────────────────────────────────────┐
│ Phase 6: Backup/Restore Service (v1.5.0)                           │
│ • Start backup scheduler (every 30 min default)                   │
│ • Start restore watcher (monitors ./restore directory)            │
│ • Wire to CacheService for region locking                         │
└───────────────────────────────────────────────────────────────────┘
      │
      ▼
     SYSTEM READY</pre>

                            <h4 class="mt-4">6.3 Failure Scenarios and Handling</h4>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Scenario</th><th>Impact</th><th>Recovery</th></tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>Graceful Shutdown</strong></td>
                                        <td>No data loss</td>
                                        <td>All pending writes complete before shutdown</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Process Kill (SIGKILL)</strong></td>
                                        <td>Minimal data loss (in-flight async writes)</td>
                                        <td>RocksDB WAL recovery, LMDB txn rollback</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Power Failure</strong></td>
                                        <td>Last few async writes may be lost</td>
                                        <td>Same as SIGKILL; persistence backends are crash-safe</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Disk Full</strong></td>
                                        <td>Write failures logged</td>
                                        <td>Clear disk space, restart; existing data preserved</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Corrupted Database</strong></td>
                                        <td>Startup fails</td>
                                        <td>Restore from backup; RocksDB has repair tools</td>
                                    </tr>
                                </tbody>
                            </table>

                            <h4 class="mt-4">6.4 Best Practices for Data Safety</h4>
                            <div class="row">
                                <div class="col-md-6">
                                    <div class="card border-success">
                                        <div class="card-header bg-success text-white"><i class="fas fa-check me-2"></i>Do</div>
                                        <div class="card-body">
                                            <ul class="mb-0">
                                                <li>Use RocksDB or LMDB for production</li>
                                                <li>Enable scheduled compaction</li>
                                                <li>Monitor disk space usage</li>
                                                <li>Set up regular backups</li>
                                                <li>Use graceful shutdown</li>
                                                <li>Size JVM heap appropriately</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-6">
                                    <div class="card border-danger">
                                        <div class="card-header bg-danger text-white"><i class="fas fa-times me-2"></i>Don't</div>
                                        <div class="card-body">
                                            <ul class="mb-0">
                                                <li>Use <code>memory</code> backend for important data</li>
                                                <li>Ignore disk space warnings</li>
                                                <li>Kill process with SIGKILL regularly</li>
                                                <li>Disable memory watcher in production</li>
                                                <li>Skip startup compaction for large datasets</li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>

                <!-- 7. Concurrency Safety & Shutdown (v1.3.3) -->
                <section id="concurrency-safety" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header text-white" style="background: linear-gradient(135deg, #10b981 0%, #3b82f6 100%);">
                            <h2 class="mb-0"><i class="fas fa-shield-alt me-2"></i>7. Concurrency Safety & Shutdown (v1.3.3)</h2>
                        </div>
                        <div class="card-body">
                            <p>Kuber v1.3.3 introduces comprehensive concurrency controls to prevent database corruption and ensure data integrity.</p>
                            
                            <h4>7.1 Persistence Operation Locking</h4>
                            <p>A centralized <code>PersistenceOperationLock</code> coordinates all operations that affect the persistence store:</p>
                            
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Operation</th><th>Lock Type</th><th>Blocks</th></tr>
                                </thead>
                                <tbody>
                                    <tr><td><strong>Compaction</strong></td><td><span class="badge bg-danger">Exclusive Global</span></td><td>All other operations</td></tr>
                                    <tr><td><strong>Shutdown</strong></td><td><span class="badge bg-danger">Exclusive Global</span></td><td>All other operations</td></tr>
                                    <tr><td><strong>Cleanup/Expiration</strong></td><td><span class="badge bg-warning text-dark">Shared Global</span></td><td>Only during exclusive ops</td></tr>
                                    <tr><td><strong>Autoload</strong></td><td><span class="badge bg-info">Per-Region</span></td><td>Same-region operations</td></tr>
                                    <tr><td><strong>Region Loading</strong></td><td><span class="badge bg-info">Per-Region</span></td><td>Queries to that region</td></tr>
                                </tbody>
                            </table>
                            
                            <h4 class="mt-4">7.2 Shutdown Orchestrator</h4>
                            <p>The <code>ShutdownOrchestrator</code> ensures orderly shutdown in the <strong>exact reverse order</strong> of startup:</p>
                            
                            <div class="row">
                                <div class="col-md-6">
                                    <div class="card border-primary">
                                        <div class="card-header bg-primary text-white">Startup Order</div>
                                        <div class="card-body">
                                            <ol class="mb-0">
                                                <li>Persistence Maintenance</li>
                                                <li>Cache Service (recovery)</li>
                                                <li>Event Publishing</li>
                                                <li>Redis Protocol Server</li>
                                                <li>Autoload Service</li>
                                            </ol>
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-6">
                                    <div class="card border-success">
                                        <div class="card-header bg-success text-white">Shutdown Order (Reverse)</div>
                                        <div class="card-body">
                                            <ol class="mb-0">
                                                <li>Stop Autoload Service</li>
                                                <li>Stop Redis Protocol Server</li>
                                                <li>Stop Event Publishing</li>
                                                <li>Persist Cache Data</li>
                                                <li>Close Persistence Store</li>
                                            </ol>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="alert alert-info mt-3">
                                <i class="fas fa-clock me-2"></i>
                                Each shutdown phase has a <strong>5-second delay</strong> to ensure in-flight operations complete and buffers flush.
                            </div>
                            
                            <h4 class="mt-4">8.3 Region Loading Guards</h4>
                            <p>During startup, queries to a region that's still loading will <strong>wait</strong> until loading completes:</p>
                            <pre class="bg-dark text-white p-3 rounded">
GET key (region 'orders' is loading)
    │
    └── waitForRegionReady('orders', 30s timeout)
            │
            ├── Still loading? → Wait 100ms, check again
            │
            └── Loaded! → Proceed with GET operation</pre>
                        </div>
                    </div>
                </section>

                <!-- 8. Startup & Shutdown (v1.3.6) -->
                <section id="shutdown-utility" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header text-white" style="background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);">
                            <h2 class="mb-0"><i class="fas fa-power-off me-2"></i>8. Startup &amp; Shutdown (v1.3.6)</h2>
                        </div>
                        <div class="card-body">
                            <p>Kuber v1.3.6 provides comprehensive management scripts and orchestrated startup/shutdown sequences for reliable operation.</p>
                            
                            <h4>8.1 Management Scripts</h4>
                            <p>Scripts are located in the <code>scripts/</code> folder:</p>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Script</th><th>Platform</th><th>Description</th></tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><code>kuber-start.sh</code></td>
                                        <td><span class="badge bg-success">Linux/Mac</span></td>
                                        <td>Start Kuber server with JVM options</td>
                                    </tr>
                                    <tr>
                                        <td><code>kuber-start.bat</code></td>
                                        <td><span class="badge bg-primary">Windows</span></td>
                                        <td>Start Kuber server on Windows</td>
                                    </tr>
                                    <tr>
                                        <td><code>kuber-shutdown.sh</code></td>
                                        <td><span class="badge bg-success">Linux/Mac</span></td>
                                        <td>Graceful shutdown via file or API</td>
                                    </tr>
                                    <tr>
                                        <td><code>kuber-shutdown.bat</code></td>
                                        <td><span class="badge bg-primary">Windows</span></td>
                                        <td>Graceful shutdown on Windows</td>
                                    </tr>
                                    <tr>
                                        <td><code>kuber-status.sh</code></td>
                                        <td><span class="badge bg-success">Linux/Mac</span></td>
                                        <td>Check server status</td>
                                    </tr>
                                </tbody>
                            </table>
                            
                            <h4 class="mt-4">8.2 Startup Script Usage</h4>
                            <pre class="bg-dark text-white p-3 rounded">
# Basic startup
./scripts/kuber-start.sh

# With options
./scripts/kuber-start.sh -m 4g -p prod              # 4GB heap, prod profile
./scripts/kuber-start.sh -d -l /var/log/kuber       # Daemon mode with log dir
./scripts/kuber-start.sh --redis-port 6381          # Custom Redis port
./scripts/kuber-start.sh --debug                     # Enable remote debugging</pre>
                            
                            <h4 class="mt-4">8.3 Startup Sequence</h4>
                            <p>Kuber follows an orchestrated startup sequence managed by <code>StartupOrchestrator</code>:</p>
                            <pre class="bg-dark text-white p-3 rounded">
Application Start
       │
       ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 1: Infrastructure Setup                               │
│  • Initialize logging & configuration                        │
│  • Connect to ZooKeeper (if replication enabled)            │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 2: Persistence Maintenance (Sequential)               │
│  • Initialize RocksDB/SQLite stores per region              │
│  • Run compaction sequentially (one region at a time)       │
│  • Clean expired entries                                     │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 3: Cache Recovery (Sequential)                        │
│  • Load persisted entries into memory (one region at a time)│
│  • Build off-heap key indexes                                │
│  • Prime negative cache                                      │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 4: Service Activation                                 │
│  • Start Event Publishing (Kafka, RabbitMQ, etc.)           │
│  • Start Redis Protocol Server (port 6380)                  │
│  • Start HTTP/REST Server (port 8080)                       │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 5: Background Services                                │
│  • Start Autoload Service (file monitoring)                 │
│  • Start Scheduled Tasks (compaction, cleanup)              │
│  • Start Shutdown File Watcher                              │
│  • System Ready!                                             │
└─────────────────────────────────────────────────────────────┘</pre>
                            
                            <h4 class="mt-4">8.4 Shutdown Methods</h4>
                            <table class="table table-bordered">
                                <thead class="table-light">
                                    <tr><th>Method</th><th>Command</th><th>Use Case</th></tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><span class="badge bg-success">File-based</span></td>
                                        <td><code>touch ./kuberdata/kuber.shutdown</code></td>
                                        <td>Local shutdown, scripted automation</td>
                                    </tr>
                                    <tr>
                                        <td><span class="badge bg-primary">REST API</span></td>
                                        <td><code>POST /api/admin/shutdown</code></td>
                                        <td>Remote shutdown, CI/CD pipelines</td>
                                    </tr>
                                    <tr>
                                        <td><span class="badge bg-warning text-dark">Signal</span></td>
                                        <td><code>SIGTERM</code> / <code>Ctrl+C</code></td>
                                        <td>Container orchestration (K8s, Docker)</td>
                                    </tr>
                                    <tr>
                                        <td><span class="badge bg-info">Script</span></td>
                                        <td><code>./scripts/kuber-shutdown.sh</code></td>
                                        <td>Convenient wrapper with options</td>
                                    </tr>
                                </tbody>
                            </table>
                            
                            <h4 class="mt-4">8.5 Shutdown Script Usage</h4>
                            <pre class="bg-dark text-white p-3 rounded">
# File-based shutdown (default)
./scripts/kuber-shutdown.sh

# With reason for logging
./scripts/kuber-shutdown.sh -r "Maintenance window"

# API-based shutdown
./scripts/kuber-shutdown.sh -a -k your-api-key

# REST API directly
curl -X POST http://localhost:8080/api/admin/shutdown \
  -H "X-API-Key: your-api-key"</pre>
                            
                            <div class="alert alert-info">
                                <i class="fas fa-info-circle me-2"></i>
                                Kuber checks for the shutdown file every 5 seconds (configurable). When detected, it initiates graceful shutdown and deletes the file automatically.
                            </div>
                            
                            <h4 class="mt-4">8.6 Shutdown Sequence</h4>
                            <p>Shutdown proceeds in <strong>exact reverse order</strong> of startup with configurable delays:</p>
                            <pre class="bg-dark text-white p-3 rounded">
Shutdown Triggered (file/API/signal)
         │
         ▼
┌─────────────────────────────────────────┐
│  1. Signal Shutdown                      │
│     Block new persistence operations     │
├─────────────────────────────────────────┤
│  ── Wait 5 seconds ──                   │
├─────────────────────────────────────────┤
│  2. Stop Autoload Service               │
│     Stop file monitoring & processing    │
├─────────────────────────────────────────┤
│  ── Wait 5 seconds ──                   │
├─────────────────────────────────────────┤
│  3. Stop Redis Protocol Server          │
│     Reject new client connections        │
├─────────────────────────────────────────┤
│  ── Wait 5 seconds ──                   │
├─────────────────────────────────────────┤
│  4. Stop Event Publishing               │
│     Flush queues, close connections      │
├─────────────────────────────────────────┤
│  ── Wait 5 seconds ──                   │
├─────────────────────────────────────────┤
│  5. Persist Cache Data                  │
│     Save all entries to persistence      │
├─────────────────────────────────────────┤
│  ── Wait 5 seconds ──                   │
├─────────────────────────────────────────┤
│  6. Close Persistence Store             │
│     Close RocksDB/SQLite handles         │
└─────────────────────────────────────────┘
         │
         ▼
    Application Exit (~30 seconds total)</pre>
                            
                            <h4 class="mt-4">8.7 Configuration</h4>
                            <pre class="bg-light p-3 rounded">
kuber:
  base:
    datadir: ./kuberdata              # Base directory for all data
  shutdown:
    file-enabled: true                # Enable file-based shutdown
    file-path: ${kuber.base.datadir}/kuber.shutdown  # Path to shutdown signal file
    check-interval-ms: 5000           # Check interval (5 seconds)
    api-enabled: true                 # Enable REST API shutdown
    phase-delay-seconds: 5            # Delay between shutdown phases</pre>
                        </div>
                    </div>
                </section>

                <!-- 9. Event Publishing -->
                <section id="event-publishing" class="mb-5">
                    <div class="card shadow-sm">
                        <div class="card-header text-white" style="background: linear-gradient(135deg, #f59e0b 0%, #ef4444 100%);">
                            <h2 class="mb-0"><i class="fas fa-broadcast-tower me-2"></i>9. Event Publishing (v1.3.2)</h2>
                        </div>
                        <div class="card-body">
                            <p>Kuber can publish cache events (insert, update, delete) to external messaging systems asynchronously via a pluggable publisher architecture.</p>
                            
                            <h4>9.1 Supported Publishers</h4>
                            <div class="row">
                                <div class="col-md-4 mb-2"><span class="badge bg-success me-2">Kafka</span> High-throughput streaming</div>
                                <div class="col-md-4 mb-2"><span class="badge bg-warning text-dark me-2">ActiveMQ</span> Enterprise JMS</div>
                                <div class="col-md-4 mb-2"><span class="badge bg-info me-2">RabbitMQ</span> AMQP messaging</div>
                                <div class="col-md-4 mb-2"><span class="badge bg-primary me-2">IBM MQ</span> Enterprise MQ</div>
                                <div class="col-md-4 mb-2"><span class="badge bg-secondary me-2">File</span> JSON Lines output</div>
                            </div>
                            
                            <h4 class="mt-4">9.2 Publishing Architecture</h4>
                            <pre class="bg-dark text-white p-3 rounded">
CacheService.set() / delete()
         │
         │ Submit to async queue (non-blocking)
         ▼
┌─────────────────────────────┐
│  Publishing Thread Pool     │
│  (kuber-event-publisher-N)  │
└────────────┬────────────────┘
             │
             ▼
      PublisherRegistry
             │
    ┌────┬───┴───┬────┬────┐
    ▼    ▼       ▼    ▼    ▼
 Kafka  AMQ  RabbitMQ IBM  File
                      MQ</pre>

                            <h4 class="mt-4">8.3 EventPublisher Interface</h4>
                            <pre class="bg-light p-2 rounded small"><code>public interface EventPublisher {
    String getType();        // "kafka", "rabbitmq", "file"
    void initialize();       // Setup at startup
    boolean isEnabledForRegion(String region);
    void publish(String region, CachePublishingEvent event);
}</code></pre>

                            <h4 class="mt-4">7.4 Key Design Principles</h4>
                            <ul>
                                <li><strong>Interface-driven:</strong> Easy to add new publisher implementations</li>
                                <li><strong>Non-blocking:</strong> Cache operations never wait for publishing</li>
                                <li><strong>Multi-destination:</strong> One region can publish to multiple destinations</li>
                                <li><strong>Isolated failures:</strong> One publisher failing doesn't affect others</li>
                                <li><strong>Per-region config:</strong> Different destinations per region</li>
                            </ul>

                            <div class="alert alert-info mt-3">
                                <i class="fas fa-book me-2"></i>
                                <strong>Full Documentation:</strong> See <a href="/help/publishing" class="alert-link">Event Publishing Guide</a> 
                                for complete configuration reference and examples.
                            </div>
                        </div>
                    </div>
                </section>

                <!-- Navigation -->
                <div class="mt-5 text-center">
                    <a href="/help/architecture" class="btn btn-outline-primary">
                        <i class="fas fa-arrow-left me-2"></i>Architecture
                    </a>
                    <a href="/help" class="btn btn-outline-secondary ms-2">
                        <i class="fas fa-home me-2"></i>Help Home
                    </a>
                    <a href="/help/publishing" class="btn btn-outline-warning ms-2">
                        Event Publishing<i class="fas fa-arrow-right ms-2"></i>
                    </a>
                </div>
            </div>
        </div>

        <!-- Footer -->
        <footer class="py-4 mt-5 border-top">
            <div class="row">
                <div class="col-md-6">
                    <h6><i class="fas fa-database me-2"></i><span th:text="${appName} ?: 'Kuber'">Kuber</span> Distributed Cache</h6>
                    <p class="text-muted small mb-0">Version 1.7.4</p>
                </div>
                <div class="col-md-6 text-end">
                    <p class="text-muted small mb-0">
                        Copyright &copy; 2025-2030, All Rights Reserved<br>
                        Ashutosh Sinha | <a href="mailto:ajsinha@gmail.com">ajsinha@gmail.com</a><br>
                        <span class="badge bg-warning text-dark">Patent Pending</span>
                    </p>
                </div>
            </div>
        </footer>
    </div>
</main>

<th:block th:replace="~{layout :: scripts}"></th:block>

</body>
</html>
